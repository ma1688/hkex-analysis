#!/usr/bin/env python3
"""
å¯é…ç½®çš„æ–‡æ¡£è¿‡æ»¤å™¨ - æ”¯æŒè‡ªå®šä¹‰è¿‡æ»¤è§„åˆ™
åŸºäº YAML é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§è¿‡æ»¤æ–¹å¼
"""

import sys
import re
import os
import yaml
import hashlib
from pathlib import Path
from typing import Tuple, Optional, Dict, Any
from datetime import datetime

# ç¼“å­˜é…ç½®
_FILTER_CACHE = {}
_CONFIG_HASH = None
_CONFIG_PATH = None

class ConfigurableDocumentFilter:
    """å¯é…ç½®çš„æ–‡æ¡£è¿‡æ»¤å™¨"""

    def __init__(self, pdf_path: str, config_path: str = None):
        self.pdf_path = Path(pdf_path)
        self.filename = self.pdf_path.stem
        self.config_path = config_path or self._get_default_config_path()
        self.config = self._load_config()
        self.cached_decision = None

    def _get_default_config_path(self) -> str:
        """è·å–é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„"""
        current_dir = Path(__file__).parent
        config_dir = current_dir.parent / "config"
        return str(config_dir / "document_filter.yaml")

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        global _CONFIG_HASH

        if not os.path.exists(self.config_path):
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
            print("ğŸ“ ä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()

        # è¯»å–é…ç½®æ–‡ä»¶
        with open(self.config_path, 'r', encoding='utf-8') as f:
            content = f.read()
            config = yaml.safe_load(content)

        # è®¡ç®—é…ç½®æ–‡ä»¶å“ˆå¸Œï¼Œç”¨äºæ£€æµ‹é…ç½®å˜æ›´
        _CONFIG_HASH = hashlib.md5(content.encode('utf-8')).hexdigest()

        return config

    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®ï¼ˆå½“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶ä½¿ç”¨ï¼‰"""
        return {
            'filter_mode': {'mode': 'hybrid'},
            'document_types': {
                'whitelist': [],
                'blacklist': [],
                'default_action': 'process'
            },
            'keyword_filters': {
                'blacklist': [],
                'whitelist': [],
                'enabled': True
            },
            'pattern_filters': {
                'blacklist_patterns': [],
                'whitelist_patterns': [],
                'enabled': True
            },
            'file_filters': {
                'size': {'enabled': False},
                'date': {'enabled': False},
                'filename_length': {'enabled': False}
            },
            'special_rules': {
                'force_process_patterns': [],
                'force_skip_patterns': [],
                'enabled': True
            },
            'logging': {
                'verbose': True,
                'log_decisions': True
            },
            'cache': {
                'enabled': True,
                'ttl': 3600
            }
        }

    def _check_config_changed(self) -> bool:
        """æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å‘ç”Ÿå˜åŒ–"""
        global _CONFIG_HASH
        if not os.path.exists(self.config_path):
            return False

        with open(self.config_path, 'r', encoding='utf-8') as f:
            content = f.read()
            current_hash = hashlib.md5(content.encode('utf-8')).hexdigest()

        return current_hash != _CONFIG_HASH

    def _get_cached_decision(self) -> Optional[Tuple[bool, str]]:
        """è·å–ç¼“å­˜çš„å†³ç­–"""
        if not self.config.get('cache', {}).get('enabled', True):
            return None

        if self._check_config_changed():
            # é…ç½®å·²å˜æ›´ï¼Œæ¸…ç©ºç¼“å­˜
            global _FILTER_CACHE
            _FILTER_CACHE.clear()
            return None

        cache_key = f"{self.pdf_path}_{_CONFIG_HASH}"
        return _FILTER_CACHE.get(cache_key)

    def _cache_decision(self, decision: Tuple[bool, str]):
        """ç¼“å­˜å†³ç­–ç»“æœ"""
        if not self.config.get('cache', {}).get('enabled', True):
            return

        global _FILTER_CACHE
        cache_key = f"{self.pdf_path}_{_CONFIG_HASH}"
        _FILTER_CACHE[cache_key] = decision

    def _parse_document_type(self) -> str:
        """è§£ææ–‡æ¡£ç±»å‹ï¼ˆå¤ç”¨ä¹‹å‰çš„é€»è¾‘ï¼‰"""
        filename_lower = self.filename.lower()

        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šæ›´å…·ä½“çš„ç±»å‹ä¼˜å…ˆäºé€šç”¨ç±»å‹

        # 1. éå¸¸é‡å¤§æ”¶è´­/å‡ºå”®ï¼ˆæœ€å…·ä½“ï¼‰
        if any(keyword in filename_lower for keyword in [
            'éå¸¸é‡å¤§æ”¶è´­', 'éå¸¸é‡å¤§å‡ºå”®', 'éå¸¸é‡å¤§æ”¶è³¼', 'very_substantial_acquisition', 'very_substantial_disposal'
        ]):
            if 'æ”¶è´­' in filename_lower or 'æ”¶è³¼' in filename_lower or 'acquisition' in filename_lower:
                return 'very_substantial_acquisition'
            else:
                return 'very_substantial_disposal'

        # 2. å…³è¿äº¤æ˜“
        elif any(keyword in filename_lower for keyword in [
            'å…³è¿äº¤æ˜“', 'connected_transaction', 'é—œé€£äº¤æ˜“'
        ]):
            return 'connected_transaction'

        # 3. é¡»äºˆæŠ«éœ²äº¤æ˜“
        elif any(keyword in filename_lower for keyword in [
            'é¡»äºˆæŠ«éœ²äº¤æ˜“', 'é ˆäºˆæŠ«éœ²äº¤æ˜“', 'disclosable_transaction'
        ]):
            return 'disclosable_transaction'

        # 4. æ”¶è´­
        elif any(keyword in filename_lower for keyword in [
            'æ”¶è´­', 'æ”¶è³¼', 'acquisition', 'è³¼ä½µ', 'å¹¶è´­'
        ]):
            return 'acquisition'

        # 5. å‡ºå”®/å¤„ç½®
        elif any(keyword in filename_lower for keyword in [
            'å‡ºå”®', 'å¤„ç½®', 'è™•ç½®', 'disposal', 'å‡ºå”®è³‡ç”¢'
        ]):
            return 'disposal'

        # 6. ä¾›è‚¡
        elif any(keyword in filename_lower for keyword in [
            'ä¾›è‚¡', 'rights', 'rights_issue', 'rights issue'
        ]):
            return 'rights'

        # 7. é…å”®
        elif any(keyword in filename_lower for keyword in [
            'é…å”®', 'placing'
        ]):
            return 'placing'

        # 8. IPO/æ‹›è‚¡/ä¸Šå¸‚
        elif any(keyword in filename_lower for keyword in [
            'ipo', 'æ‹›è‚¡', 'ä¸Šå¸‚', 'æ‹›è‚¡æ›¸', 'æ‹›è‚¡ä¹¦'
        ]):
            return 'ipo'

        # 9. åˆè‚¡/è‚¡æœ¬æ•´åˆ
        elif any(keyword in filename_lower for keyword in [
            'åˆè‚¡', 'consolidation', 'è‚¡æœ¬æ•´åˆ', 'è‚¡æœ¬é‡çµ„', 'è‚¡æœ¬é‡ç»„', 'share consolidation'
        ]):
            return 'consolidation'

        # 10. æ‹†è‚¡ï¼ˆåˆ†è‚¡ï¼‰
        elif any(keyword in filename_lower for keyword in [
            'æ‹†è‚¡', 'åˆ†è‚¡', 'share split', 'stock split', 'è‚¡ä»½åˆ†æ‹†', 'share_split'
        ]):
            return 'split'

        # 11. è‚¡ä»½å›è´­
        elif any(keyword in filename_lower for keyword in [
            'è‚¡ä»½å›è´­', 'è‚¡ä»½å›è³¼', 'share repurchase', 'è‚¡ä»½å›è³¼è¦ç´„', 'share_repurchase'
        ]):
            return 'share_repurchase'

        # 12. è‚¡æ¯åˆ†æ´¾
        elif any(keyword in filename_lower for keyword in [
            'è‚¡æ¯', 'åˆ†æ´¾', 'dividend', 'æ´¾æ¯', 'æœ«æœŸè‚¡æ¯', 'ç‰¹åˆ¥è‚¡æ¯'
        ]):
            return 'dividend'

        # 13. è‚¡æœ¬ç¼©å‡
        elif any(keyword in filename_lower for keyword in [
            'è‚¡æœ¬ç¼©å‡', 'è‚¡æœ¬ç¸®æ¸›', 'capital reduction', 'è‚¡æœ¬å‰Šæ¸›', 'capital_reduction'
        ]):
            return 'capital_reduction'

        # 14. è´­è‚¡æƒè®¡åˆ’
        elif any(keyword in filename_lower for keyword in [
            'è´­è‚¡æƒ', 'è³¼è‚¡æ¬Š', 'share option', 'è³¼è‚¡æ¬Šè¨ˆåŠƒ', 'share option scheme', 'share_option', 'share_option_scheme'
        ]):
            return 'share_option'

        # 15. å…¶ä»–
        else:
            return 'other'

    def _check_document_type_filter(self) -> Optional[Tuple[bool, str]]:
        """æ£€æŸ¥æ–‡æ¡£ç±»å‹è¿‡æ»¤"""
        doc_type = self._parse_document_type()
        doc_config = self.config.get('document_types', {})
        whitelist = doc_config.get('whitelist') or []
        blacklist = doc_config.get('blacklist') or []
        default_action = doc_config.get('default_action', 'process')

        # é»‘åå•æ£€æŸ¥
        if doc_type in blacklist:
            return (False, f"æ–‡æ¡£ç±»å‹åœ¨é»‘åå•ä¸­: {doc_type}")

        # ç™½åå•æ£€æŸ¥
        if doc_type in whitelist:
            return (True, f"æ–‡æ¡£ç±»å‹åœ¨ç™½åå•ä¸­: {doc_type}")

        # é»˜è®¤å¤„ç†
        return (default_action == 'process', f"æ–‡æ¡£ç±»å‹æœªæŒ‡å®šï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥: {default_action}")

    def _check_keyword_filter(self) -> Optional[Tuple[bool, str]]:
        """æ£€æŸ¥å…³é”®è¯è¿‡æ»¤"""
        keyword_config = self.config.get('keyword_filters', {})
        if not keyword_config.get('enabled', True):
            return None

        filename_lower = self.filename.lower()
        whitelist = keyword_config.get('whitelist') or []
        blacklist = keyword_config.get('blacklist') or []

        # ç™½åå•å…³é”®è¯æ£€æŸ¥
        for keyword in whitelist:
            if keyword in filename_lower:
                return (True, f"ç™½åå•å…³é”®è¯åŒ¹é…: {keyword}")

        # é»‘åå•å…³é”®è¯æ£€æŸ¥
        for keyword in blacklist:
            if keyword in filename_lower:
                return (False, f"é»‘åå•å…³é”®è¯åŒ¹é…: {keyword}")

        return None

    def _check_pattern_filter(self) -> Optional[Tuple[bool, str]]:
        """æ£€æŸ¥æ¨¡å¼è¿‡æ»¤ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰"""
        pattern_config = self.config.get('pattern_filters', {})
        if not pattern_config.get('enabled', True):
            return None

        whitelist_patterns = pattern_config.get('whitelist_patterns') or []
        blacklist_patterns = pattern_config.get('blacklist_patterns') or []

        # ç™½åå•æ¨¡å¼æ£€æŸ¥
        for pattern in whitelist_patterns:
            if re.search(pattern, self.filename):
                return (True, f"ç™½åå•æ¨¡å¼åŒ¹é…: {pattern}")

        # é»‘åå•æ¨¡å¼æ£€æŸ¥
        for pattern in blacklist_patterns:
            if re.search(pattern, self.filename):
                return (False, f"é»‘åå•æ¨¡å¼åŒ¹é…: {pattern}")

        return None

    def _check_file_filters(self) -> Optional[Tuple[bool, str]]:
        """æ£€æŸ¥æ–‡ä»¶å±æ€§è¿‡æ»¤"""
        file_config = self.config.get('file_filters', {})

        # æ–‡ä»¶å¤§å°è¿‡æ»¤
        size_config = file_config.get('size', {})
        if size_config.get('enabled', False):
            file_size = self.pdf_path.stat().st_size
            min_size = size_config.get('min_size', 0)
            max_size = size_config.get('max_size', float('inf'))

            if file_size < min_size:
                return (False, f"æ–‡ä»¶è¿‡å°: {file_size} bytes < {min_size} bytes")
            if file_size > max_size:
                return (False, f"æ–‡ä»¶è¿‡å¤§: {file_size} bytes > {max_size} bytes")

        # æ–‡ä»¶åé•¿åº¦è¿‡æ»¤
        length_config = file_config.get('filename_length', {})
        if length_config.get('enabled', False):
            filename_len = len(self.filename)
            min_length = length_config.get('min_length', 0)
            max_length = length_config.get('max_length', 1000)

            if filename_len < min_length:
                return (False, f"æ–‡ä»¶åè¿‡çŸ­: {filename_len} < {min_length}")
            if filename_len > max_length:
                return (False, f"æ–‡ä»¶åè¿‡é•¿: {filename_len} > {max_length}")

        return None

    def _check_special_rules(self) -> Optional[Tuple[bool, str]]:
        """æ£€æŸ¥ç‰¹æ®Šè§„åˆ™"""
        special_config = self.config.get('special_rules', {})
        if not special_config.get('enabled', True):
            return None

        filename_lower = self.filename.lower()
        force_process = special_config.get('force_process_patterns') or []
        force_skip = special_config.get('force_skip_patterns') or []

        # å¼ºåˆ¶å¤„ç†æ£€æŸ¥
        for pattern in force_process:
            if pattern.lower() in filename_lower:
                return (True, f"ç‰¹æ®Šè§„åˆ™-å¼ºåˆ¶å¤„ç†: {pattern}")

        # å¼ºåˆ¶è·³è¿‡æ£€æŸ¥
        for pattern in force_skip:
            if pattern.lower() in filename_lower:
                return (False, f"ç‰¹æ®Šè§„åˆ™-å¼ºåˆ¶è·³è¿‡: {pattern}")

        return None

    def should_process(self) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ–‡æ¡£æ˜¯å¦åº”è¯¥å¤„ç†

        Returns:
            (should_process, reason) - (æ˜¯å¦å¤„ç†, åŸå› è¯´æ˜)
        """
        # æ£€æŸ¥ç¼“å­˜
        cached = self._get_cached_decision()
        if cached:
            return cached

        filter_mode = self.config.get('filter_mode', {}).get('mode', 'hybrid')

        # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥å„ç§è¿‡æ»¤è§„åˆ™
        checks = [
            self._check_special_rules,      # ç‰¹æ®Šè§„åˆ™ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
            self._check_document_type_filter,  # æ–‡æ¡£ç±»å‹è¿‡æ»¤
            self._check_keyword_filter,     # å…³é”®è¯è¿‡æ»¤
            self._check_pattern_filter,     # æ¨¡å¼è¿‡æ»¤
            self._check_file_filters,       # æ–‡ä»¶å±æ€§è¿‡æ»¤
        ]

        decisions = []
        for check in checks:
            result = check()
            if result:
                decisions.append(result)

        # æ ¹æ®è¿‡æ»¤æ¨¡å¼å†³å®šæœ€ç»ˆç»“æœ
        if filter_mode == 'whitelist':
            # ç™½åå•æ¨¡å¼ï¼šå¿…é¡»æœ‰åŒ¹é…çš„è§„åˆ™æ‰å¤„ç†
            should_process = any(d[0] for d in decisions)
            reason = "ç™½åå•æ¨¡å¼: " + ("åŒ¹é…ç™½åå•è§„åˆ™" if should_process else "æœªåŒ¹é…ä»»ä½•ç™½åå•è§„åˆ™")
        elif filter_mode == 'blacklist':
            # é»‘åå•æ¨¡å¼ï¼šåªè¦åŒ¹é…é»‘åå•å°±è·³è¿‡
            should_process = not any(not d[0] for d in decisions)
            reason = "é»‘åå•æ¨¡å¼: " + ("æœªåŒ¹é…é»‘åå•è§„åˆ™" if should_process else "åŒ¹é…é»‘åå•è§„åˆ™")
        else:  # hybrid æ¨¡å¼
            # æ··åˆæ¨¡å¼ï¼šç™½åå•ä¼˜å…ˆï¼Œç„¶ååº”ç”¨é»‘åå•
            process_decisions = [d for d in decisions if d[0]]
            skip_decisions = [d for d in decisions if not d[0]]

            if process_decisions:
                # æœ‰åŒ¹é…çš„å¤„ç†è§„åˆ™
                should_process = True
                reason = process_decisions[0][1]
            elif skip_decisions:
                # æœ‰åŒ¹é…çš„è·³è¿‡è§„åˆ™
                should_process = False
                reason = skip_decisions[0][1]
            else:
                # æ²¡æœ‰åŒ¹é…çš„è§„åˆ™ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥
                doc_config = self.config.get('document_types', {})
                default_action = doc_config.get('default_action', 'process')
                should_process = (default_action == 'process')
                reason = f"æ··åˆæ¨¡å¼: æœªåŒ¹é…è§„åˆ™ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥ ({default_action})"

        # ç¼“å­˜å†³ç­–ç»“æœ
        self._cache_decision((should_process, reason))

        # è®°å½•æ—¥å¿—
        if self.config.get('logging', {}).get('log_decisions', True):
            status = "âœ… å¤„ç†" if should_process else "â­ï¸ è·³è¿‡"
            print(f"[è¿‡æ»¤] {status} - {self.filename} - {reason}")

        return (should_process, reason)

    def print_decision(self) -> bool:
        """æ‰“å°è¿‡æ»¤å†³ç­–"""
        should_process, reason = self.should_process()

        print("=" * 80)
        print("ğŸ“„ å¯é…ç½®æ–‡æ¡£è¿‡æ»¤æ£€æŸ¥")
        print("=" * 80)
        print(f"æ–‡ä»¶: {self.filename}")
        print(f"è·¯å¾„: {self.pdf_path}")
        print(f"æ–‡æ¡£ç±»å‹: {self._parse_document_type()}")
        print(f"è¿‡æ»¤æ¨¡å¼: {self.config.get('filter_mode', {}).get('mode', 'hybrid')}")
        print("-" * 80)
        print(f"å†³ç­–: {'âœ… åº”è¯¥å¤„ç†' if should_process else 'â­ï¸ è·³è¿‡å¤„ç†'}")
        print(f"åŸå› : {reason}")
        print("=" * 80)

        return should_process


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python document_filter_configurable.py <pdf_path> [config_path]")
        print("è¿”å›ç : 0=åº”è¯¥å¤„ç†, 1=åº”è¯¥è·³è¿‡")
        sys.exit(2)

    pdf_path = sys.argv[1]
    config_path = sys.argv[2] if len(sys.argv) > 2 else None

    if not Path(pdf_path).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        sys.exit(2)

    filter_obj = ConfigurableDocumentFilter(pdf_path, config_path)
    should_process = filter_obj.print_decision()

    # è¿”å›ç ï¼š0=åº”è¯¥å¤„ç†ï¼Œ1=åº”è¯¥è·³è¿‡
    sys.exit(0 if should_process else 1)


if __name__ == '__main__':
    main()
