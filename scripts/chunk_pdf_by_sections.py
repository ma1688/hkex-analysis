#!/usr/bin/env python3
"""
ä¾›è‚¡PDFæŒ‰ç« èŠ‚åˆ‡å—è„šæœ¬ï¼ˆæ— å‘é‡ç‰ˆæœ¬ï¼‰
ç”¨æ³•ï¼špython chunk_pdf_by_sections.py <pdf_path> <stock_code>
"""

import json
import re
import sys
import uuid
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Tuple

import clickhouse_connect
import fitz  # PyMuPDF

# å¯¼å…¥é¡¹ç›®é…ç½®
sys.path.insert(0, str(Path(__file__).parent.parent))
from src.config.settings import get_settings

# ====== é…ç½® ======
settings = get_settings()
CLICKHOUSE_HOST = settings.clickhouse_host
CLICKHOUSE_PORT = settings.clickhouse_port
CLICKHOUSE_DB = settings.clickhouse_database
CLICKHOUSE_USER = settings.clickhouse_user
CLICKHOUSE_PASSWORD = settings.clickhouse_password

# ====== ç« èŠ‚ç±»å‹å…³é”®è¯æ˜ å°„ ======
SECTION_TYPE_KEYWORDS = {
    'terms': ['ä¾›è‚¡', 'è®¤è´­', 'æ¡æ¬¾', 'ä¾›è‚¡è¯¦æƒ…', 'å‚ä¸ä¾›è‚¡', 'é…å”®'],
    'timetable': ['æ—¶é—´è¡¨', 'é¢„æœŸæ—¶é—´è¡¨', 'é‡è¦æ—¥æœŸ', 'æ—¥ç¨‹'],
    'underwriting': ['åŒ…é”€', 'æ‰¿é…', 'ä¿èäºº', 'åŒ…é”€å•†'],
    'financials': ['è´¢åŠ¡', 'ä¸šç»©', 'è´¢åŠ¡èµ„æ–™', 'å€ºåŠ¡', 'å‚µå‹™', 'è¥è¿èµ„é‡‘', 'ç‡Ÿé‹è³‡é‡‘', 'è´¢åŠ¡æ¦‚è¦', 'è²¡å‹™è³‡æ–™',
                   'è²¿æ˜“å‰æ™¯'],
    'risk_factors': ['é£é™©å› ç´ ', 'æŠ•èµ„é£é™©', 'ä¸»è¦é£é™©', 'ä¸åˆ©å˜åŠ¨', 'ä¸åˆ©è®Šå‹•'],
    'suspension': ['æš‚åœåŠç†', 'è¿‡æˆ·ç™»è®°', 'æš‚åœè¿‡æˆ·'],
    'use_of_proceeds': ['å‹Ÿé›†èµ„é‡‘', 'æ‰€å¾—æ¬¾é¡¹', 'èµ„é‡‘ç”¨é€”'],
    'management': ['è‘£äº‹', 'é«˜çº§ç®¡ç†å±‚', 'é«˜ç´šç®¡ç†å±¤', 'è‘£äº‹æœåŠ¡', 'è‘£äº‹æœå‹™'],
    'company_info': ['å…¬å¸èµ„æ–™', 'å…¬å¸è³‡æ–™', 'å…¬å¸ä¿¡æ¯'],
    'legal': ['è´£ä»»å£°æ˜', 'è²¬ä»»è²æ˜', 'æ³•å¾‹', 'ä¸“å®¶', 'å°ˆå®¶'],
    'contracts': ['é‡å¤§åˆçº¦', 'é‡å¤§åˆç´„', 'åˆåŒ'],
    'disclosure': ['æƒç›ŠæŠ«éœ²', 'æ¬Šç›ŠæŠ«éœ²', 'æŠ«éœ²'],
    'market': ['å¸‚åœºä»·æ ¼', 'å¸‚å ´åƒ¹æ ¼', 'è‚¡ä»·'],
    'interests': ['ç«äº‰æƒç›Š', 'ç«¶çˆ­æ¬Šç›Š', 'åˆ©ç›Šå†²çª'],
    'documents': ['å±•ç¤ºæ–‡ä»¶', 'é€å‘ˆ', 'æ–‡ä»¶'],
    'appendix': ['é™„å½•', 'é™„ä»¶', 'è£œå……è³‡æ–™'],
    'misc': ['å…¶ä»–äº‹é …', 'å…¶ä»–äº‹é¡¹', 'æ‚é¡¹'],  # æ–°å¢ï¼šæ˜ç¡®çš„å…¶ä»–ç±»
}

# ====== ç« èŠ‚æ ‡é¢˜æ­£åˆ™æ¨¡å¼ ======
SECTION_PATTERNS = [
    # ä¸­æ–‡æ•°å­—ä¸»ç« èŠ‚ï¼šä¸€ã€äºŒã€ä¸‰ã€... ï¼ˆå¿…é¡»æœ‰"ã€"åˆ†éš”ï¼Œä¸”æ ‡é¢˜è‡³å°‘2å­—ç¬¦ï¼‰
    (r'^([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)[ã€]\s*(.{2,})$', 1),
    # æ‹¬å·ç« èŠ‚ï¼šï¼ˆä¸€ï¼‰ï¼ˆäºŒï¼‰ï¼ˆä¸‰ï¼‰ï¼ˆæ ‡é¢˜è‡³å°‘2å­—ç¬¦ï¼‰
    (r'^[ï¼ˆ(]([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)[)ï¼‰]\s*(.{2,})$', 2),
    # æ•°å­—ç« èŠ‚ï¼š1. 2. 3. ï¼ˆ1-2ä½æ•°å­—+ç‚¹å·+éæ•°å­—å¼€å¤´çš„æ ‡é¢˜ï¼‰
    (r'^(\d{1,2})\.\s+([^\d].{2,})$', 3),
]


class PDFSectionChunker:
    """PDFç« èŠ‚åˆ‡å—å¤„ç†å™¨"""

    def __init__(self, pdf_path: str, stock_code: str):
        self.pdf_path = Path(pdf_path)
        self.stock_code = stock_code
        self.doc = None
        self.doc_id = None
        self.ch_client = None

    def connect_clickhouse(self):
        """è¿æ¥ClickHouse"""
        print(f"ğŸ“¡ è¿æ¥ClickHouse: {CLICKHOUSE_HOST}:{CLICKHOUSE_PORT}/{CLICKHOUSE_DB}")
        self.ch_client = clickhouse_connect.get_client(
            host=CLICKHOUSE_HOST,
            port=CLICKHOUSE_PORT,
            database=CLICKHOUSE_DB,
            username=CLICKHOUSE_USER,
            password=CLICKHOUSE_PASSWORD
        )
        print("âœ… ClickHouseè¿æ¥æˆåŠŸ")

    def open_pdf(self):
        """æ‰“å¼€PDFæ–‡æ¡£"""
        if not self.pdf_path.exists():
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {self.pdf_path}")

        print(f"ğŸ“„ æ‰“å¼€PDF: {self.pdf_path.name}")
        self.doc = fitz.open(self.pdf_path)
        print(f"   æ€»é¡µæ•°: {len(self.doc)}")

    def generate_doc_id(self) -> str:
        """ç”Ÿæˆæ–‡æ¡£ID"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        random_suffix = uuid.uuid4().hex[:8]
        return f"{self.stock_code}_{timestamp}_{random_suffix}"

    def extract_metadata_from_filename(self) -> Dict:
        """ä»æ–‡ä»¶åæå–å…ƒä¿¡æ¯"""
        filename = self.pdf_path.stem
        full_filename = self.pdf_path.name  # åŒ…å«æ‰©å±•åçš„å®Œæ•´æ–‡ä»¶å

        # æå–æ—¥æœŸï¼ˆYYYY-MM-DDæ ¼å¼ï¼‰
        date_match = re.search(r'(\d{4}-\d{2}-\d{2})', filename)
        publish_date = datetime.strptime(date_match.group(1),
                                         '%Y-%m-%d').date() if date_match else datetime.now().date()

        # æå–å…¬å¸åï¼ˆè‚¡ç¥¨ä»£ç åçš„ç¬¬ä¸€ä¸ªä¸­æ–‡ç‰‡æ®µï¼‰
        company_match = re.search(rf'{self.stock_code}_(.+?)_', filename)
        company_name = company_match.group(1) if company_match else ''

        # åˆ¤æ–­æ˜¯å¦åŒ…é”€ï¼ˆæ›´å‡†ç¡®çš„åˆ¤æ–­ï¼‰
        # "éåŒ…éŠ·" ä¼˜å…ˆçº§é«˜äº "åŒ…éŠ·"
        if 'éåŒ…éŠ·' in full_filename or 'éåŒ…é”€' in full_filename:
            is_underwritten = False
        elif 'åŒ…éŠ·' in full_filename or 'åŒ…é”€' in full_filename:
            is_underwritten = True
        else:
            is_underwritten = False
        sub_type = 'underwritten' if is_underwritten else 'non-underwritten'

        # æå–ä¾›è‚¡æ¯”ä¾‹ï¼ˆå¤šç§æ¨¡å¼ï¼‰
        rights_ratio = ''
        # æ¨¡å¼1: æ¯æŒæœ‰ä¸€(1)è‚¡ç¶“èª¿æ•´è‚¡ä»½ç²ç™¼å››(4)è‚¡
        ratio_match1 = re.search(r'æ¯æŒæœ‰.{0,5}[ï¼ˆ(]?(\d+)[)ï¼‰]?.{0,10}ç²ç™¼.{0,5}[ï¼ˆ(]?(\d+)[)ï¼‰]?.?è‚¡', full_filename)
        if ratio_match1:
            rights_ratio = f"{ratio_match1.group(1)}:{ratio_match1.group(2)}"
        else:
            # æ¨¡å¼2: ç®€åŒ–ç‰ˆ
            ratio_match2 = re.search(r'(\d+).?è‚¡.+?(\d+).?è‚¡', full_filename)
            if ratio_match2:
                rights_ratio = f"{ratio_match2.group(1)}:{ratio_match2.group(2)}"

        return {
            'publish_date': publish_date,
            'company_name': company_name,
            'sub_type': sub_type,
            'rights_ratio': rights_ratio,
            'title': filename
        }

    def detect_section_level(self, line: str) -> Tuple[int, str, str]:
        """
        æ£€æµ‹ç« èŠ‚æ ‡é¢˜åŠå±‚çº§
        è¿”å›: (å±‚çº§, ç« èŠ‚ç¼–å·, ç« èŠ‚æ ‡é¢˜)
        """
        line = line.strip()

        for pattern, level in SECTION_PATTERNS:
            match = re.match(pattern, line)
            if match:
                if len(match.groups()) == 2:
                    section_num = match.group(1)
                    section_title = match.group(2).strip()
                    return (level, section_num, section_title)

        return (0, '', '')

    def classify_section_type(self, title: str) -> str:
        """æ ¹æ®æ ‡é¢˜å…³é”®è¯åˆ†ç±»ç« èŠ‚ç±»å‹"""
        for section_type, keywords in SECTION_TYPE_KEYWORDS.items():
            if any(kw in title for kw in keywords):
                return section_type
        return 'other'

    def extract_sections(self) -> List[Dict]:
        """æå–æ–‡æ¡£çš„æ‰€æœ‰ç« èŠ‚"""
        sections = []
        current_section = None
        section_index = 0

        print("\nğŸ” å¼€å§‹æå–ç« èŠ‚...")

        for page_num in range(len(self.doc)):
            page = self.doc[page_num]
            text = page.get_text()

            # æŒ‰è¡Œå¤„ç†
            lines = text.split('\n')

            for line in lines:
                level, section_num, section_title = self.detect_section_level(line)

                # æ£€æµ‹åˆ°æ–°ç« èŠ‚
                if level > 0:
                    # ä¿å­˜ä¸Šä¸€ä¸ªç« èŠ‚
                    if current_section:
                        sections.append(current_section)

                    # åˆ›å»ºæ–°ç« èŠ‚
                    section_type = self.classify_section_type(section_title)
                    current_section = {
                        'section_id': str(uuid.uuid4()),
                        'section_index': section_index,
                        'section_level': level,
                        'section_num': section_num,
                        'section_title': section_title,
                        'section_type': section_type,
                        'content': '',
                        'page_start': page_num + 1,
                        'page_end': page_num + 1
                    }
                    section_index += 1

                    print(f"   [{section_index}] Lv{level} {section_type:12s} | {section_num} {section_title}")

                # è¿½åŠ å†…å®¹åˆ°å½“å‰ç« èŠ‚
                elif current_section:
                    current_section['content'] += line + '\n'
                    current_section['page_end'] = page_num + 1

        # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
        if current_section:
            sections.append(current_section)

        print(f"\nâœ… å…±æå– {len(sections)} ä¸ªç« èŠ‚")
        return sections

    def insert_document_metadata(self, metadata: Dict, total_sections: int):
        """æ’å…¥æ–‡æ¡£å…ƒä¿¡æ¯"""
        print("\nğŸ’¾ æ’å…¥æ–‡æ¡£å…ƒä¿¡æ¯åˆ° documents_v2...")

        # åŒ¹é…æœ€æ–°è¡¨ç»“æ„ï¼ˆæ— embeddingå­—æ®µï¼‰
        data = [[
            self.doc_id,  # doc_id
            metadata['title'],  # title
            self.stock_code,  # stock_code
            metadata['company_name'],  # company_name
            'rights',  # document_type
            metadata['sub_type'],  # document_subtype
            metadata['publish_date'],  # announcement_date
            datetime.now(),  # processing_date
            str(self.pdf_path),  # file_path
            self.pdf_path.stat().st_size if self.pdf_path.exists() else 0,  # file_size
            len(self.doc),  # page_count
            'completed',  # processing_status
            '',  # error_message
            total_sections,  # section_count
            0,  # total_chars (æš‚æ—¶ä¸º0)
            json.dumps({  # metadata (JSONæ ¼å¼)
                'rights_ratio': metadata['rights_ratio'],
                'processing_version': '2.0',
                'source_system': 'hkex'
            }, ensure_ascii=False)
        ]]

        self.ch_client.insert(
            'documents_v2',
            data,
            column_names=[
                'doc_id', 'title', 'stock_code', 'company_name', 'document_type',
                'document_subtype', 'announcement_date', 'processing_date', 'file_path',
                'file_size', 'page_count', 'processing_status', 'error_message',
                'section_count', 'total_chars', 'metadata'
            ]
        )
        print("âœ… æ–‡æ¡£å…ƒä¿¡æ¯å·²æ’å…¥")

    def check_if_processed(self) -> bool:
        """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²å¤„ç†ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰"""
        try:
            # é€šè¿‡æ–‡ä»¶è·¯å¾„æŸ¥è¯¢
            result = self.ch_client.query(
                f"SELECT count() FROM documents_v2 WHERE file_path = '{str(self.pdf_path)}'"
            )
            count = result.result_rows[0][0]
            return count > 0
        except Exception:
            return False

    def insert_sections(self, sections: List[Dict]):
        """æ‰¹é‡æ’å…¥ç« èŠ‚æ•°æ®ï¼ˆå¸¦è¿›åº¦æç¤ºï¼‰"""
        total = len(sections)
        print(f"\nğŸ’¾ æ’å…¥ {total} ä¸ªç« èŠ‚åˆ° document_sections...")

        # æ‰¹é‡æ’å…¥ï¼ˆæé«˜æ€§èƒ½ï¼‰
        batch_size = 50
        for i in range(0, total, batch_size):
            batch = sections[i:i + batch_size]
            data = []

            for section in batch:
                data.append([
                    section['section_id'],  # section_id
                    self.doc_id,  # doc_id
                    'rights',  # document_type
                    section['section_type'],  # section_type
                    '',  # section_subtype
                    section['section_title'],  # section_title
                    section['section_index'],  # section_index
                    section['page_start'],  # page_start
                    section['page_end'],  # page_end
                    section['content'],  # content
                    '',  # content_hash
                    len(section['content']),  # char_count
                    0,  # word_count
                    section['section_level'],  # priority
                    'normal',  # importance
                    1.0,  # confidence
                    'regex',  # identification_method
                    json.dumps({  # metadata (JSONæ ¼å¼)
                        'section_num': section['section_num'],
                        'has_table': False,
                        'table_count': 0
                    }, ensure_ascii=False)
                ])

            self.ch_client.insert(
                'document_sections',
                data,
                column_names=[
                    'section_id', 'doc_id', 'document_type', 'section_type',
                    'section_subtype', 'section_title', 'section_index',
                    'page_start', 'page_end', 'content', 'content_hash',
                    'char_count', 'word_count', 'priority', 'importance',
                    'confidence', 'identification_method', 'metadata'
                ]
            )

            # è¿›åº¦æç¤º
            progress = min(i + batch_size, total)
            percentage = (progress / total) * 100
            print(f"   [{progress}/{total}] {percentage:.0f}%", end='\r')

        print(f"\nâœ… ç« èŠ‚æ•°æ®å·²æ’å…¥å®Œæˆ")

    def verify_integrity(self):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        print(f"\nğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...")

        # 1. éªŒè¯æ–‡æ¡£è®°å½•
        doc_count = self.ch_client.query(
            f"SELECT count() FROM documents_v2 WHERE doc_id = '{self.doc_id}'"
        ).result_rows[0][0]

        if doc_count != 1:
            raise ValueError(f"æ–‡æ¡£è®°å½•å¼‚å¸¸: æœŸæœ›1æ¡ï¼Œå®é™…{doc_count}æ¡")

        # 2. éªŒè¯ç« èŠ‚è®°å½•æ•°
        section_count = self.ch_client.query(
            f"SELECT count() FROM document_sections WHERE doc_id = '{self.doc_id}'"
        ).result_rows[0][0]

        expected_count = self.ch_client.query(
            f"SELECT section_count FROM documents_v2 WHERE doc_id = '{self.doc_id}'"
        ).result_rows[0][0]

        if section_count != expected_count:
            raise ValueError(f"ç« èŠ‚æ•°ä¸åŒ¹é…: æœŸæœ›{expected_count}æ¡ï¼Œå®é™…{section_count}æ¡")

        # 3. éªŒè¯ç« èŠ‚è¿ç»­æ€§
        indices = self.ch_client.query(
            f"SELECT section_index FROM document_sections WHERE doc_id = '{self.doc_id}' ORDER BY section_index"
        ).result_rows

        for i, (idx,) in enumerate(indices):
            if idx != i:
                raise ValueError(f"ç« èŠ‚ç´¢å¼•ä¸è¿ç»­: æœŸæœ›{i}ï¼Œå®é™…{idx}")

        print(f"âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        print(f"   æ–‡æ¡£è®°å½•: {doc_count}æ¡")
        print(f"   ç« èŠ‚è®°å½•: {section_count}æ¡")
        print(f"   ç´¢å¼•è¿ç»­: æ˜¯")

    def process(self, skip_if_exists: bool = True):
        """
        å®Œæ•´å¤„ç†æµç¨‹ï¼ˆå¸¦æ–­ç‚¹ç»­ä¼ ï¼‰
        
        Args:
            skip_if_exists: å¦‚æœæ–‡æ¡£å·²å­˜åœ¨ï¼Œæ˜¯å¦è·³è¿‡å¤„ç†
        """
        try:
            # 1. è¿æ¥æ•°æ®åº“
            self.connect_clickhouse()

            # 2. æ–­ç‚¹ç»­ä¼ æ£€æŸ¥
            if skip_if_exists and self.check_if_processed():
                print(f"\nâ­ï¸  æ–‡æ¡£å·²å¤„ç†ï¼Œè·³è¿‡: {self.pdf_path.name}")
                print(f"   å¦‚éœ€é‡æ–°å¤„ç†ï¼Œè¯·å…ˆåˆ é™¤æ•°æ®åº“ä¸­çš„è®°å½•")
                return

            # 3. æ‰“å¼€PDF
            self.open_pdf()

            # 4. ç”Ÿæˆdoc_id
            self.doc_id = self.generate_doc_id()
            print(f"\nğŸ†” æ–‡æ¡£ID: {self.doc_id}")

            # 5. æå–å…ƒä¿¡æ¯
            metadata = self.extract_metadata_from_filename()
            print(f"\nğŸ“‹ å…ƒä¿¡æ¯:")
            print(f"   å…¬å¸: {metadata['company_name']}")
            print(f"   æ—¥æœŸ: {metadata['publish_date']}")
            print(f"   ç±»å‹: {metadata['sub_type']}")
            print(f"   æ¯”ä¾‹: {metadata['rights_ratio'] if metadata['rights_ratio'] else 'æœªæå–åˆ°'}")

            # 6. æå–ç« èŠ‚
            sections = self.extract_sections()

            # 7. æ’å…¥æ•°æ®åº“
            self.insert_document_metadata(metadata, len(sections))
            self.insert_sections(sections)

            # 8. å®Œæ•´æ€§éªŒè¯
            self.verify_integrity()

            print(f"\nâœ… å¤„ç†å®Œæˆï¼")
            print(f"   æ–‡æ¡£ID: {self.doc_id}")
            print(f"   æ–‡ä»¶: {self.pdf_path.name}")

            # 9. æ˜¾ç¤ºç¤ºä¾‹æŸ¥è¯¢
            print(f"\nğŸ“Š æŸ¥è¯¢ç¤ºä¾‹:")
            print(
                f"   SELECT section_type, section_title FROM document_sections WHERE doc_id = '{self.doc_id}' ORDER BY section_index;")

        except Exception as e:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
        finally:
            if self.doc:
                self.doc.close()
            if self.ch_client:
                self.ch_client.close()


def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python chunk_pdf_by_sections.py <pdf_path> <stock_code>")
        print("ç¤ºä¾‹: python chunk_pdf_by_sections.py '../HKEX/00328/ä¾›è‚¡/xxx.pdf' 00328")
        sys.exit(1)

    pdf_path = sys.argv[1]
    stock_code = sys.argv[2]

    chunker = PDFSectionChunker(pdf_path, stock_code)
    chunker.process()


if __name__ == '__main__':
    main()
